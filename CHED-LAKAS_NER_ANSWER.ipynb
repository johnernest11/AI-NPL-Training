{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbQZh_FrDAmC"
   },
   "source": [
    "## Activity 1 (Topic 2) : Named Entity Recognition (NER using Spacy)  ###\n",
    "---\n",
    "This exercise will give demonstrate how NLTK can be used to extract NER from documents. it will also give the participants some experience in testing and adjusting the parameters of the NLTK NER tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muzpwyEb0KSC"
   },
   "source": [
    "### Step 1 : Importing and Loading Spacy\n",
    "---\n",
    "\n",
    "During processing, spaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off – whereas “U.K.” should remain one token. Each Doc consists of individual tokens, and we can iterate over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJd8l4fy0JR2",
    "outputId": "b0d811e9-e859-4cb7-d10f-614d32a5203c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2wqwCTQzLns"
   },
   "source": [
    "### Step 2 : linguistic annotations in Spacy\n",
    "---\n",
    "spaCy provides a variety of linguistic annotations to give you insights into a text’s grammatical structure. This includes the word types, like the parts of speech, and how the words are related to each other. For example, if you’re analyzing text, it makes a huge difference whether a noun is the subject of a sentence, or the object – or whether “google” is used as a verb, or refers to the website or company in a specific context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RquTjRyyZ5R",
    "outputId": "24037f92-c173-486d-a33a-73a44eedcc09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN dobj\n",
      "startup NOUN dep\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJKKIGCvzRN5"
   },
   "source": [
    "### Step 3 : Tokenization in Spacy\n",
    "---\n",
    "During processing, spaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off – whereas “U.K.” should remain one token. Each Doc consists of individual tokens, and we can iterate over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30Q2l9Ebyras",
    "outputId": "545d48e0-056b-4028-d0a8-a01ee95ab4f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBc0_g5FzeqI"
   },
   "source": [
    "### Step 4 : Named Entity Recognition using Spacy\n",
    "---\n",
    "A named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title. spaCy can recognize various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn’t always work perfectly and might need some tuning later, depending on your use case.\n",
    "\n",
    "Named entities are available as the ents property of a Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AsVSd9173Qgp"
   },
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "  if doc.ents:\n",
    "    for ent in doc.ents:\n",
    "      print(ent.text+' - '+str(ent.start_char)+' - '+str(ent.end_char)+str(ent.label_)+' - '+str(spacy.explain(ent.label_)))\n",
    "  else:\n",
    "    print(\"No Named entities Found\")         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYBqSIjCzrmp",
    "outputId": "61ec8064-ac1d-420d-9a54-e7eb5efcaef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n",
      "\n",
      "\n",
      "\n",
      "Washington, DC - 12 - 26GPE - Countries, cities, states\n",
      "next May - 27 - 35DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - 43 - 66ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "ner = spacy.load(\"en_core_web_sm\")\n",
    "doc = ner(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "doc2 = ner(u'May I go to Washington, DC next May to see the Washington Monument?') \n",
    "show_ents(doc2)\n",
    "#for ent in doc.ents:\n",
    "#    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XvmTb_TEyTW"
   },
   "source": [
    "### Step 4 : Interface for testing Named Entity Recognition using Spacy\n",
    "---\n",
    "\n",
    "Enter a sample text and see if Spacy can identify the embedded NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "14g8yyi2E-9O",
    "outputId": "d23cd012-56f0-4af8-b926-a2fa94aa8dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sample text:hello world\n",
      "Raw Text Data: \n",
      " hello world \n",
      "\n",
      "No Named entities Found\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jagoodkid/miniforge3/lib/python3.10/site-packages/spacy/displacy/__init__.py:215: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">hello world</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sample text:*\n",
      "Raw Text Data: \n",
      " * \n",
      "\n",
      "No Named entities Found\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">*</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sample text:?\n",
      "Raw Text Data: \n",
      " ? \n",
      "\n",
      "No Named entities Found\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program ended\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "sample_text = 'This is a sample text'\n",
    "while sample_text != '?':\n",
    "  sample_text = input('Enter a sample text:')\n",
    "  print('Raw Text Data: \\n',sample_text,'\\n')\n",
    "  doc = ner(sample_text) \n",
    "  show_ents(doc)\n",
    "  print('\\n')\n",
    "  displacy.render(doc,style=\"ent\",jupyter=True)\n",
    "print(\"Program ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise_Day2_Topic4_2_(NER_using_Spacy).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
